{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd, walk\n",
    "from pandas import read_csv, concat\n",
    "from plotnine import ggplot, aes, geom_line, theme_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = []  # List for storing the data set locations\n",
    "data_sets_directory = f\"{getcwd()}/datasets\" # Home directory of the data \n",
    "for (root, dirs, files) in walk(data_sets_directory):    # Looping over directories \n",
    "    for file in files:  # Looping through the files \n",
    "        file_path = root + \"/\" + file   # Setting up the path \n",
    "        data_sets.append(file_path)  # Extending the stored directoriess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_res = concat([read_csv(data_set) for data_set in data_sets])    \n",
    "annual_res.sort_values([*annual_res.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_res = read_csv(\"Intcal20.csv\")\n",
    "mixed_res = mixed_res[mixed_res[\"cal\"] > annual_res[\"year\"].min() - 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         cal  d14c  d14csig\n",
       " 0     1725.0  12.2      2.3\n",
       " 1     1724.0   9.0      2.1\n",
       " 2     1724.0  14.0      2.3\n",
       " 3     1723.0  12.0      2.3\n",
       " 4     1722.0  11.2      2.1\n",
       " ...      ...   ...      ...\n",
       " 9985 -1676.0  16.6      2.0\n",
       " 9986 -1677.0  16.8      1.9\n",
       " 9987 -1678.0  15.9      2.0\n",
       " 9988 -1679.0  18.9      1.8\n",
       " 9989 -1679.0  17.4      2.0\n",
       " \n",
       " [6838 rows x 3 columns],\n",
       "       year  d14c  sig_d14c\n",
       " 0  -5411.0  90.1       2.8\n",
       " 1  -5409.0  97.7       2.9\n",
       " 2  -5407.0  96.9       2.9\n",
       " 3  -5405.0  93.3       2.9\n",
       " 4  -5403.0  90.6       2.8\n",
       " ..     ...   ...       ...\n",
       " 32  -637.0   3.1       1.7\n",
       " 33  -636.0   6.5       1.7\n",
       " 34  -635.0   2.4       1.7\n",
       " 35  -634.0   1.8       2.4\n",
       " 36  -633.0   2.4       2.3\n",
       " \n",
       " [1012 rows x 3 columns])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_res, annual_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a 100 year block and test the code. So I could fill in the 25 years before and 25 years after with the Intcal20 interpolated curve. Take all of Intcal20 and place the actual data into the interpolated data. This would require rescaling the data with a linear curve or something along those lines. Only test the injection recovery at te real years. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear combination of the basis vectors provided by the template, linear trend and constant.\n",
    "$Ax = b$ simple linear regression with a 50 by 3 design matrix that is dotted with a 3 long position vector to produce the predicted d14c. The first row is just the template. The second is just rows and the final is just the year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample the data with gaussian noise of the same magnitude as the error bars. Plot the amplitdues as a histogram. Calculate the chi squared statsitic and then do just trend and mean and calculate the difference in chi squared statistic. I choose the significance threshold of the resulting distribution.This gives the false positive rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you inject a number of small events and see if they are detected based on the thresholds you decided. This gives you the false negative rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating this for every year I can plot the year vs the 50% false positive amplitude of the event. Interpolate over all of the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c4d728f571dc14aecd61e9c5a335d0795680d56501238c7b0344daa2ef0c43f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ticktack': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
