{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ticktack\n",
    "import pandas\n",
    "from jax.numpy import arange, sin, pi, array, greater, less, equal, where, mean\n",
    "from jax import jacrev, grad\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic question is what is the probability of detecting consecutive events based on the distribution of the data. The first step then will be to determine the distribution of the data. This will be done be resampling the points after the event has been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sine(t, p):\n",
    "    \"\"\"\n",
    "    Generates a simple sinusoidal production function. p is an array containing the amplitude of the production sinusoid and the phase of the sinusoid.\n",
    "    \"\"\"\n",
    "    return 1.88 + p[0] * 1.88 * sin(2 * pi / 11 * t + p[1])\n",
    "\n",
    "def rect(t, p):\n",
    "    \"\"\"\n",
    "    Generates a rectangular miyake event. p is an array that contains the start and end times as well as the height of the production function \n",
    "    \"\"\"\n",
    "    condition = equal(greater(t, p[0]), less(t, p[1]))\n",
    "    return where(condition, p[3], 0.0)\n",
    "\n",
    "def prod(t, *args):\n",
    "    amplitude, phase, start, end, height = tuple(args)\n",
    "    sine_params = array([amplitude, phase])\n",
    "    rect_params = array([start, end, height])\n",
    "    return sine(t, sine_params) + rect(t, rect_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_samples = 48                  # 4 samples per month\n",
    "sample_times = arange(-360.0, 790.0)  # Times at which to collect samples\n",
    "growth_bools = array([0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0])\n",
    "params = array([1.0, 1.25, 772.0, 775.0, 40.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbm = ticktack.load_presaved_model(\"Guttler14\", production_rate_units=\"atoms/cm^2/s\")\n",
    "cbm.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "miyake = pandas.read_csv(\"Miyake12.csv\", sep=\" \")   # Reading the data from the Miyake 2012\n",
    "DC14 = array([*miyake.d14c])                        # JAX array for manipulation\n",
    "SDC14 = array([*miyake.sig_d14c])                   # JAx array for manipulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So below is where I minimize the $\\chi^{2}$ statistic using an ODE integration style approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(params): \n",
    "    model, steady_state = cbm.run(sample_times, annual_samples,     # Running the carbon box model\n",
    "        production=prod, steady_state_production=1.88, args=params)\n",
    "\n",
    "    troposphere = cbm.bin_data( # Bins the data into annual values\n",
    "        model[:, 2],    # Selecting only the years that I have data for \n",
    "        annual_samples, # Number of samples per year \n",
    "        sample_times,   # Times to return the binned values for \n",
    "        growth_bools    # Boolean mask of growth seasons\n",
    "    )\n",
    "    \n",
    "    troposphere = troposphere[-29:-1]   # slicing only the period of interest \n",
    "    troposphere = 1000 * (troposphere - steady_state[2]) / steady_state[2]  # Normalising the data \n",
    "    troposphere = troposphere + mean(array([*miyake[\"d14c\"][0:4]])) # Offseting the data to match \n",
    "    return 0.5 * sum(((DC14 - troposphere) / SDC14) ** 2)   # Log likelhood as chi-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(log_likelihood, params, method='Nelder-Mead', options={'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 13125.811198\n",
      "         Iterations: 7\n",
      "         Function evaluations: 76\n",
      "         Gradient evaluations: 63\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      fun: 13125.81119771305\n",
       " hess_inv: array([[1.72623680e-01, 6.83015026e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [6.83015026e-04, 1.30490598e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00]])\n",
       "      jac: array([ 0.06198596, -5.44565391,  0.        ,  0.        ,  0.        ])\n",
       "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
       "     nfev: 76\n",
       "      nit: 7\n",
       "     njev: 63\n",
       "   status: 2\n",
       "  success: False\n",
       "        x: array([ 10.77749084,   1.96963468, 772.        , 775.        ,\n",
       "        40.        ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize(log_likelihood, params, method='BFGS', jac=grad(log_likelihood), options={'disp': True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_model = ticktack.fitting.SingleFitter(cbm)\n",
    "mcmc_model.load_data(\"Miyake12.csv\")\n",
    "mcmc_model.prepare_function(model=prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = mcmc_model.MarkovChainSampler(params, likelihood = mcmc_model.log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Amplitude ($atoms/cm^2/s$)\", \"Phase (yr)\", \"Start Date (yr)\", \"End Date (yr)\", \"Height ($atoms/cm^2/s$)\"]\n",
    "fig = mcmc_model.chain_summary(sampler, 20, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_model.plot_recovery(sampler, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from here the plan is to first of all find the ideal sinusoidal model based on the data points until the event. I then run this model and subtract it away from the data allowing me to determine the signal to noise ratio of the entire data instead of a subset. Then I simulate a series of events and minimize the $\\chi^{2}$ to determine the best fitting rectangular event. In addition I will have some criterion for the $\\chi^{2}$ as to when an event is detected allowing me to identify the minimum parameters of the event. I will then plot a contour plot of the $\\chi^{2}$ in the 2 dimensional parameter space. This will be the final product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to minimize the $\\chi^{2}$. After working so hard to get the `mcmc` I'm going to try and use this. The problem is because I was not using ticktack I can now immensly simplify the code by using the `SingleFitter` implementations provided by Q."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To minimize the $\\chi^{2}$ statistic I will need to isolate the data before the event and use this to determine the $\\sin$ parameters. This is going to require modifications to the `prod` function and also will require a better understanding of the plotting backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be easiest to modify the file. It is nice I must say to have got fucking nowhere all day. I'm going to go and pack now after merging these changes on github."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c4d728f571dc14aecd61e9c5a335d0795680d56501238c7b0344daa2ef0c43f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ticktack': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
