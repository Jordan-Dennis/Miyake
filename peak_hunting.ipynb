{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ticktack\n",
    "from jax.numpy import array, pi, exp, sin, mean, median, var, arange, sum\n",
    "from numpy import random\n",
    "from scipy.stats import ttest_ind\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from plotnine import ggplot, facet_wrap, labs, aes, theme_bw, geom_tile, scale_color_cmap\n",
    "from os import listdir, getcwd, walk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic question is what is the probability of detecting consecutive events based on the distribution of the data. The first step then will be to determine the distribution of the data. This will be done be resampling the points after the event has been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = { # This dictionary contains the units for the fluxes and production function\n",
    "    \"Guttler14\": {  # Units of the Guttler 2014 paper\n",
    "        \"production_rate_units\": \"atoms/cm^2/s\",    # Units of the production rate \n",
    "        \"flow_rate_units\": \"Gt/yr\"                  # Units of the fluxes\n",
    "    },\n",
    "    \"Brehm21\": {    # Units used by the Brehm, et. al. paper\n",
    "        \"production_rate_units\": \"kg/yr\",    # Units of the production rate\n",
    "        \"flow_rate_units\": \"Gt/yr\"           # Units of the fluxes\n",
    "    },\n",
    "    \"Buntgen18\": {  # The units used by the Buntgen 2018 paper\n",
    "        \"production_rate_units\": \"atoms/cm^2/s\",    # Units of the production function\n",
    "        \"flow_rate_units\": \"Gt/yr\"                  # Units of the fluxes \n",
    "    },\n",
    "    \"Miyake17\": {   # The units used by the Miyake 2017 et. al. paper\n",
    "        \"production_rate_units\": \"atoms/cm^2/s\",    # Units of the production function \n",
    "        \"flow_rate_units\": \"1/yr\"                   # Units of the fluxes.\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = []  # List for storing the data set locations\n",
    "data_sets_directory = \"{}/datasets\".format(getcwd()) # Home directory of the data \n",
    "for (root, dirs, files) in walk(data_sets_directory):    # Looping over directories \n",
    "    for file in files:  # Looping through the files \n",
    "        file_path = root + \"/\" + file   # Setting up the path \n",
    "        data_sets.append(file_path)  # Extending the stored directoriess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below will also have a `shape` parameter eventually. First however I want to get this running. Damn this really is well suited to a class structure since then I can set `self.set_annual_samples()` need to check if this has actually been implemented. The answer is __No__. I need to add the growth seasons to the `model_units` (which I might just rename `models`). This will lead to ?two? extra field `hemisphere_model` (bool) and `growth_seasons`. Alternatively this could result in a further nested dictionary like `hemispheres = {\"NH_growth\": array([]), \"SH_growth\": array([])}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model: str, datum: str):\n",
    "    cbm = ticktack.load_presaved_model( # Generating the CarbobBoxModel using ticktack\n",
    "        model,  # Name of the model as looped from the models dictionary \n",
    "        production_rate_units=models[model][\"production_rate_units\"], \n",
    "        flow_rate_units=models[model][\"flow_rate_units\"]\n",
    "    )\n",
    "\n",
    "    bayesian_model = ticktack.fitting.SingleFitter(model)   # Fitting a model \n",
    "    bayesian_model.prepare_function(model=\"simple_sinusoid\")# Generating the simple sin model\n",
    "    bayesian_model.load_data(datum)   # Loading the data into the model  \n",
    "\n",
    "    return bayesian_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_production_function(model: ticktack.fitting.SingleFitter):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        model: `str` - The `CarbonBoxModel` that is to be used\n",
    "        data: `str` - The dataset that the production function is to be fitted to (.csv)\n",
    "    Returns:\n",
    "        production: `function` - The ideal production function \n",
    "    \"\"\"\n",
    "    def mcmc_parameters():\n",
    "        \"\"\"\n",
    "        A Wrapper function to mask the initial position from the function namespace and allow for smoother `try catch`\n",
    "        \"\"\"\n",
    "        initial_parameters = array( # Array of initial parameters\n",
    "            [model.time_data[len(model.time_data) // 2], # Guessing the event start data occurs at half\n",
    "            1./12,  # This is the duration guessing 1 month\n",
    "            pi/2.,  # This is the phase \n",
    "            81./12] # This is the area \n",
    "        )\n",
    "\n",
    "        return model.MarkovChainSampler(    # An array of samples for all of the parameters\n",
    "            initial_parameters,    # Initial position within the parameters space    \n",
    "            likelihood=model.log_likelihood,   # likelihood function \n",
    "            burnin=200,                             # Truncated burnin for testing \n",
    "            production=500,                          # Truncated production for testing \n",
    "            k = 4\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        samples = mcmc_parameters()\n",
    "    except ValueError:\n",
    "        print(\"Large condition number encountered: \\n\" +\n",
    "            \"\\t Trying again:\")\n",
    "\n",
    "    parameters = {  # A dictionary of the model parameters for the `simple_sinusoid`\n",
    "        \"Start Date (yr)\": None,    # The year that the event began \n",
    "        \"Duration (yr)\": None,      # Number of years that the event occured over \n",
    "        \"Phase (yr)\": None,         # The phase shift of the sinusoidal production function \n",
    "        \"Area\": None               #? What are the units?\n",
    "    } \n",
    "\n",
    "    for i, parameter in enumerate(parameters):  # Looping through the parameters \n",
    "        parameters[parameter] = {   # Nested dictionary to store statistical information\n",
    "            \"mean\": mean(samples[:, i]),    # Storing the mean of the samples produced by mcmc\n",
    "            \"median\": median(samples[:, i]),# Storing the median in addition to the mean \n",
    "            \"variance\": var(samples[:, i])  # Storing the variance of the parameter\n",
    "        }\n",
    "    parameters[\"Steady Production\"] = model.steady_state_production   \n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def production(t: float, params: dict):\n",
    "    \"\"\"\n",
    "    The best fit production function as estimated using `mcmc`\n",
    "    \"\"\"\n",
    "    middle = params[\"Start Date (yr)\"][\"mean\"] + \\\n",
    "        params[\"Duration (yr)\"][\"mean\"] / 2.0    # Calculating the center of the event\n",
    "    height = params[\"Area\"][\"mean\"] / params[\"Duration (yr)\"][\"mean\"] # The magnitude of the event \n",
    "\n",
    "    gauss = height * exp(- ((t - middle) / (1. / 1.93516 * \\\n",
    "        params[\"Duration (yr)\"][\"mean\"])) ** 16.)   # The super-gaussian event\n",
    "\n",
    "    sine = params[\"Steady Production\"] + \\\n",
    "        0.18 * params[\"Steady Production\"] * \\\n",
    "        sin(2 * pi / 11 * t + params[\"Phase (yr)\"][\"mean\"]) # Sinusoidal component of production \n",
    "    \n",
    "    return sine + gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_residual_distribution(model: ticktack.fitting.SingleFitter, params: list):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        production: function - The production function, typically determined using `get_production_function`.\n",
    "        data: str - The file name of the data. Should be the same as the file name that was provided to `get_production_function`.\n",
    "    Returns:\n",
    "        An `mcmc` sample of the posterior distribution of the residuals, which has been fitted with a parameteric (to start) distribution that can be used to simulate noise.\n",
    "    \"\"\"\n",
    "    #* I need to work out how to include the measurement uncerainty in my parametric fitting\n",
    "    #* I also need to work out how to test for normaility\n",
    "\n",
    "    residuals = model.d14c_data - model.dc14(params)\n",
    "\n",
    "    #* Should look into mae error reporting for the variance and mean. \n",
    "    #! Should be using mcmc here to get a better estimate for the mean and the variance ext.\n",
    "\n",
    "    gaussian_error_parameters = {   # Dictionary containing the parameters of a parametric gaussian\n",
    "        \"residuals\": {   # The statistical error in the residuals \n",
    "            \"mean\": mean(residuals),    # The mean of the residuals assumed to have gaussian error\n",
    "            \"variance\": var(residuals)  # Variance of the residuals assumed to have gaussian error\n",
    "        },\n",
    "        \"error\": {  # The statistical distribution of the measurement error\n",
    "            \"mean\": mean(model.d14c_data_error),   # Mean measurement error\n",
    "            \"variance\": var(model.d14c_data_error) # Variance of measurement error \n",
    "        }\n",
    "    }\n",
    "\n",
    "    return gaussian_error_parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the error in the data measurements will have a distribution that I can use to generate imaginary error in the data. I'm not sure how this will help but it could change the way things shape out so I will implement this and keep track of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_error(model: ticktack.fitting.SingleFitter, error: dict, theoretical_dc14: array):\n",
    "    \"\"\"\n",
    "    Simulates a Miyake event based on the things that have already transpired. \n",
    "    \"\"\"   \n",
    "    random_error = random.randn(len(model.d14c_data)) * \\\n",
    "        error[\"residuals\"][\"variance\"] + error[\"residuals\"][\"mean\"] # Generating the noise \n",
    "    \n",
    "    measurement_error = random.randn(len(model.d14c_data_error)) * \\\n",
    "        error[\"error\"][\"variance\"] + error[\"error\"][\"mean\"]\n",
    "\n",
    "    data = {    # A Dictionary that I will convert to a DataFrame and return \n",
    "        \"Year\": model.time_data,        # The time series data \n",
    "        \"DC14\": theoretical_dc14 + random_error,           # Simulated C14 data\n",
    "        \"Sig_DC14\": measurement_error   # Simulated C14 measurement error\n",
    "    }\n",
    "\n",
    "    return DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_event(event: DataFrame, EDC14: array):\n",
    "    \"\"\"\n",
    "    Used to determine how likely an event is to have occured. \n",
    "    Parameters:\n",
    "        event: `DataFrame` -> A simulated event\n",
    "        EDC14: `array` -> The theoretical values \n",
    "    Returns:\n",
    "        The chi-squared of the simulated event given the EDC14 and the error in the chi-squared\n",
    "    \"\"\"\n",
    "    chi_squared = (array([*event[\"DC14\"]]) - EDC14) ** 2 / EDC14  # Calculates generalised chi squared\n",
    "    chi_squared_error = 2 * array([*event[\"Sig_DC14\"]])   # Error propagation of chi-sqaured \n",
    "    return float(sum(chi_squared)), float(sum(chi_squared_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_models = {model: models[model] for model in [\"Guttler14\", \"Miyake17\"]} # Extracting two test models\n",
    "test_data = data_sets[:2]   # Test data sets to run the test models on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Model = Guttler14 \n",
      "Current Datum = Miyake21_Finland2.csv\n",
      "Running burn-in...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:43<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running production...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:46<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Current Model = Guttler14 \n",
      "Current Datum = Miyake21_Switzerland.csv\n",
      "Running burn-in...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]/home/jordan/.local/lib/python3.8/site-packages/emcee/moves/red_blue.py:99: RuntimeWarning: invalid value encountered in double_scalars\n",
      "100%|██████████| 200/200 [00:36<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running production...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:28<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Current Model = Miyake17 \n",
      "Current Datum = Miyake21_Finland2.csv\n",
      "Running burn-in...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:14<00:00, 13.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running production...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:26<00:00, 19.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Current Model = Miyake17 \n",
      "Current Datum = Miyake21_Switzerland.csv\n",
      "Running burn-in...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]/home/jordan/.local/lib/python3.8/site-packages/emcee/moves/red_blue.py:99: RuntimeWarning: invalid value encountered in double_scalars\n",
      "100%|██████████| 200/200 [00:11<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running production...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:27<00:00, 18.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulations = {             # Holds the data farmed from the simulation \n",
    "    \"Model\": [],            # The model that was used in the simulation\n",
    "    \"Data\": [],             # Holds the name of the dataset\n",
    "    \"Height\": [],           # The peak height of the production function \n",
    "    \"Duration\": [],         # The duration of the productioin function \n",
    "    \"Chi Squared\": [],      # The chi-squared of the model \n",
    "    \"Chi Squared Error\": [] # The error in the chi-squared\n",
    "}\n",
    "\n",
    "for model in test_models:   # Looping over the models \n",
    "    for datum in test_data: # Looping over the data\n",
    "        datum_str = datum.split(\"/\")[-1]    # Just storing the csv name not the whole adress path \n",
    "        \n",
    "        print(  \n",
    "            f\"Current Model = {model} \\n\" +\n",
    "            f\"Current Datum = {datum_str}\"\n",
    "        )\n",
    "\n",
    "        model_obj = get_model(model, datum)    # Loading the model into RAM\n",
    "        production_params = get_production_function(model_obj)   # Getting the production function \n",
    "        model_obj.production = production   # Assigning the production function \n",
    "        data_error = get_residual_distribution(model_obj, [production_params])  # Getting error \n",
    "\n",
    "        for height in arange(0.1, 8.0, 0.1):   # Looping over a range of areas \n",
    "            for duration in arange(0.1, 8.0, 0.1):   # Looping over a range of durations\n",
    "                event_params = production_params.copy()             # Copying the parameters \n",
    "                event_params[\"Area\"][\"mean\"] = height * duration    # Updating the area parameter\n",
    "                event_params[\"Duration (yr)\"][\"mean\"] = duration    # Changing the duration \n",
    "\n",
    "                theoretical_dc14 = model_obj.dc14([production_params])      # Running the model \n",
    "                event = simulate_error(model_obj, data_error, theoretical_dc14)  # Running simulation \n",
    "                chi_squared, error = recover_event(event, theoretical_dc14) # getting shi \n",
    "\n",
    "                simulations[\"Data\"].append(datum_str)           # Storing the data\n",
    "                simulations[\"Model\"].append(model)              # Storing the model \n",
    "                simulations[\"Height\"].append(height)            # Storing the simulation area\n",
    "                simulations[\"Duration\"].append(duration)        # Storing the simulations duration \n",
    "                simulations[\"Chi Squared\"].append(chi_squared)  # Storing the chi-squared\n",
    "                simulations[\"Chi Squared Error\"].append(error)  # Storing chi-squared error \n",
    "\n",
    "        print(\"\\n\") # New line for nicer terminal display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations = DataFrame(simulations)\n",
    "(ggplot(simulations, aes(x=\"Height\", y=\"Duration\", fill=\"Log P\"))\n",
    "    + geom_tile()\n",
    "    + scale_color_cmap(cmap_name=\"Spectral\")\n",
    "    + facet_wrap(\"~Model + Data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel density information will enable me to get the maximum likelhood as well as the mean and median."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c4d728f571dc14aecd61e9c5a335d0795680d56501238c7b0344daa2ef0c43f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ticktack': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
