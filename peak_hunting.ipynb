{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ticktack\n",
    "from jax.numpy import array, pi, exp, sin, mean, median, var\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic question is what is the probability of detecting consecutive events based on the distribution of the data. The first step then will be to determine the distribution of the data. This will be done be resampling the points after the event has been removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I need to have a dictionary to keep track of the units for the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = { # This dictionary contains the units for the fluxes and production function\n",
    "    \"Guttler14\": {  # Units of the Guttler 2014 paper\n",
    "        \"production_rate_units\": \"atoms/cm^2/s\",    # Units of the production rate \n",
    "        \"flow_rate_units\": \"Gt/yr\"                  # Units of the fluxes\n",
    "    },\n",
    "    \"Brehm21\": {    # Units used by the Brehm, et. al. paper\n",
    "        \"production_rate_units\": \"\",    # Units of the production rate \n",
    "        \"flow_rate_units\": \"\"           # Units of the fluxes\n",
    "    },\n",
    "    \"Buntgen18\": {  # The units used by the Buntgen 2018 paper\n",
    "        \"production_rate_units\": \"\",    # Units of the production function\n",
    "        \"flow_rate_units\": \"\"           # Units of the fluxes \n",
    "    },\n",
    "    \"Miyake17\": {   # The units used by the Miyake 2017 et. al. paper\n",
    "        \"production_rate_units\": \"\",    # Units of the production function \n",
    "        \"flow_rate_units\": \"\"           # Units of the fluxes.\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below will also have a `shape` parameter eventually. First however I want to get this running. Damn this really is well suited to a class structure since then I can set `self.set_annual_samples()` need to check if this has actually been implemented. The answer is __No__. I need to add the growth seasons to the `model_units` (which I might just rename `models`). This will lead to ?two? extra field `hemisphere_model` (bool) and `growth_seasons`. Alternatively this could result in a further nested dictionary like `hemispheres = {\"NH_growth\": array([]), \"SH_growth\": array([])}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_production_function(model: str, data: str):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        model: `str` - The `CarbonBoxModel` that is to be used\n",
    "        data: `str` - The dataset that the production function is to be fitted to (.csv)\n",
    "    Returns:\n",
    "        production: `function` - The ideal production function \n",
    "    \"\"\"\n",
    "    cbm = ticktack.load_presaved_model( # Generating the CarbobBoxModel using ticktack\n",
    "        model,  # Name of the model as looped from the models dictionary \n",
    "        production_rate_units=models[model][\"production_rate_units\"], \n",
    "        flow_rate_units=models[model][\"flow_rate_units\"]\n",
    "    )\n",
    "    cbm.compile()   # Generating the transfer operator via the compile() command \n",
    "\n",
    "    mcmc_model = ticktack.fitting.SingleFitter(cbm)     # Fitting a model \n",
    "    mcmc_model.load_data(data)                          # Loading the data into the model \n",
    "    mcmc_model.prepare_function(model=\"simple_sinusoid\")# Generating the simple sin model \n",
    "\n",
    "    samples = mcmc_model.MarkovChainSampler(    # An array of samples for all of the parameters\n",
    "        array([775., 1./12, pi/2., 81./12]),    # Initial position within the parameters space    \n",
    "        likelihood=mcmc_model.log_likelihood,   # likelihood function \n",
    "        burnin=200,                             # Truncated burnin for testing \n",
    "        production=500                          # Truncated production for testing \n",
    "    )\n",
    "\n",
    "    parameters = {  # A dictionary of the model parameters for the `simple_sinusoid`\n",
    "        \"Start Date (yr)\": None,    # The year that the event began \n",
    "        \"Duration (yr)\": None,      # Number of years that the event occured over \n",
    "        \"Phase (yr)\": None,         # The phase shift of the sinusoidal production function \n",
    "        \"Area\": None               #? What are the units?\n",
    "    } \n",
    "\n",
    "    for i, parameter in enumerate(parameters):  # Looping through the parameters \n",
    "        parameters[parameter] = {   # Nested dictionary to store statistical information\n",
    "            \"mean\": mean(samples[:, i]),    # Storing the mean of the samples produced by mcmc\n",
    "            \"median\": median(samples[:, i]),# Storing the median in addition to the mean \n",
    "            \"variance\": var(samples[:, i])  # Storing the variance of the parameter\n",
    "        }\n",
    "    parameters[\"Steady Production\"] = mcmc_model.steady_state_production   \n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running burn-in...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:17<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running production...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:44<00:00, 11.19it/s]\n"
     ]
    }
   ],
   "source": [
    "params = get_production_function(\"Guttler14\", \"Miyake12.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def production(t: float):\n",
    "    \"\"\"\n",
    "    The best fit production function as estimated using `mcmc`\n",
    "    \"\"\"\n",
    "    middle = params[\"Start Date (yr)\"][\"mean\"] + \\\n",
    "        params[\"Duration (yr)\"][\"mean\"] / 2.0    # Calculating the center of the event\n",
    "    height = params[\"Area\"][\"mean\"] / params[\"Duration (yr)\"][\"mean\"] # The magnitude of the event \n",
    "\n",
    "    gauss = height * exp(- ((t - middle) / (1. / 1.93516 * \\\n",
    "        params[\"Duration (yr)\"][\"mean\"])) ** 16.)   # The super-gaussian event\n",
    "\n",
    "    sine = params[\"Steady Production\"] + \\\n",
    "        0.18 * params[\"Steady Production\"] * \\\n",
    "        sin(2 * pi / 11 * t + params[\"Phase (yr)\"][\"mean\"]) # Sinusoidal component of production \n",
    "    \n",
    "    return sine + gauss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting some inefficiency by loading the data twice. I may look into avoiding the use of the `SingleFitter` to get around this but it is not ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_residual_distribution(production, model:str, data: str):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        production: function - The production function, typically determined using `get_production_function`.\n",
    "        data: str - The file name of the data. Should be the same as the file name that was provided to `get_production_function`.\n",
    "    Returns:\n",
    "        An `mcmc` sample of the posterior distribution of the residuals, which has been fitted with a parameteric (to start) distribution that can be used to simulate noise.\n",
    "    \"\"\"\n",
    "    #* I need to work out how to include the measurement uncerainty in my parametric fitting\n",
    "    #* I also need to work out how to test for normaility\n",
    "    data = read_csv(data, sep=\" \")  # Reading the data into the namespace #! CHECK SEP\n",
    "\n",
    "    model = ticktack.load_presaved_model(model, production_rate_units=models[model][\"production_rate_units\"], flow_rate_units=models[model][\"flow_rate_untis\"])\n",
    "\n",
    "    years = array([*data[\"year\"]])  # Creating an array to fead into the production function \n",
    "    residuals = array([*data[\"d14c\"]]) - production(years)  # Calculating the residuals\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from here the plan is to first of all find the ideal sinusoidal model based on the data points until the event. I then run this model and subtract it away from the data allowing me to determine the signal to noise ratio of the entire data instead of a subset. Then I simulate a series of events and minimize the $\\chi^{2}$ to determine the best fitting rectangular event. In addition I will have some criterion for the $\\chi^{2}$ as to when an event is detected allowing me to identify the minimum parameters of the event. I will then plot a contour plot of the $\\chi^{2}$ in the 2 dimensional parameter space. This will be the final product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to minimize the $\\chi^{2}$. After working so hard to get the `mcmc` I'm going to try and use this. The problem is because I was not using ticktack I can now immensly simplify the code by using the `SingleFitter` implementations provided by Q."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To minimize the $\\chi^{2}$ statistic I will need to isolate the data before the event and use this to determine the $\\sin$ parameters. This is going to require modifications to the `prod` function and also will require a better understanding of the plotting backend."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c4d728f571dc14aecd61e9c5a335d0795680d56501238c7b0344daa2ef0c43f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ticktack': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
