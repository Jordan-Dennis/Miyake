{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ticktack\n",
    "import pandas\n",
    "from jax.numpy import arange, sin, pi, array, greater, less, equal, where, mean\n",
    "from jax import jacrev, grad\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic question is what is the probability of detecting consecutive events based on the distribution of the data. The first step then will be to determine the distribution of the data. This will be done be resampling the points after the event has been removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I need to have a dictionary to keep track of the units for the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_units = { # This dictionary contains the units for the fluxes and production function\n",
    "    \"Guttler14\": {  # Units of the Guttler 2014 paper\n",
    "        \"production_rate_units\": \"atoms/cm^2/s\",    # Units of the production rate \n",
    "        \"flow_rate_units\": \"Gt/yr\"                  # Units of the fluxes\n",
    "    },\n",
    "    \"Brehm21\": {    # Units used by the Brehm, et. al. paper\n",
    "        \"production_rate_units\": \"\",    # Units of the production rate \n",
    "        \"flow_rate_units\": \"\"           # Units of the fluxes\n",
    "    },\n",
    "    \"Buntgen18\": {  # The units used by the Buntgen 2018 paper\n",
    "        \"production_rate_units\": \"\",    # Units of the production function\n",
    "        \"flow_rate_units\": \"\"           # Units of the fluxes \n",
    "    },\n",
    "    \"Miyake17\": {   # The units used by the Miyake 2017 et. al. paper\n",
    "        \"production_rate_units\": \"\",    # Units of the production function \n",
    "        \"flow_rate_units\": \"\"           # Units of the fluxes.\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below will also have a `shape` parameter eventually. First however I want to get this running. Damn this really is well suited to a class structure since then I can set `self.set_annual_samples()` need to check if this has actually been implemented. The answer is __No__. I need to add the growth seasons to the `model_units` (which I might just rename `models`). This will lead to ?two? extra field `hemisphere_model` (bool) and `growth_seasons`. Alternatively this could result in a further nested dictionary like `hemispheres = {\"NH_growth\": array([]), \"SH_growth\": array([])}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_production_function(model: str, data: str):\n",
    "    params = array([1.0, 1.25, 772.0, 775.0, 40.0]) # An array containing the intial parameters of the production funtion #? This needs major work.\n",
    "\n",
    "    cbm = ticktack.load_presaved_model( # Generating the CarbobBoxModel using ticktack\n",
    "        model,  # Name of the model as looped from the models dictionary \n",
    "        production_rate_units=model_units[model][\"production_rate_units\"], \n",
    "        flow_rate_units=model_units[model][\"flow_rate_units\"]\n",
    "    )\n",
    "    cbm.compile()   # Generating the transfer operator via the compile() command \n",
    "\n",
    "    #? Need to double check that this will work\n",
    "    mcmc_model = ticktack.fitting.SingleFitter(cbm)     # Fitting a model \n",
    "    mcmc_model.load_data(data)                          # Loading the data into the model \n",
    "    mcmc_model.prepare_function(model=\"simple_sinusoid\")# Generating the simple sin model \n",
    "\n",
    "    sampler = mcmc_model.MarkovChainSampler(\n",
    "        params, # Initial position within the parameters space    \n",
    "        likelihood=mcmc_model.log_likelihood,   # likelihood function \n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_production_function(\"Guttler14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "miyake = pandas.read_csv(\"Miyake12.csv\", sep=\" \")   # Reading the data from the Miyake 2012\n",
    "DC14 = array([*miyake.d14c])                        # JAX array for manipulation\n",
    "SDC14 = array([*miyake.sig_d14c])                   # JAx array for manipulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So below is where I minimize the $\\chi^{2}$ statistic using an ODE integration style approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = mcmc_model.MarkovChainSampler(params, likelihood = mcmc_model.log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Amplitude ($atoms/cm^2/s$)\", \"Phase (yr)\", \"Start Date (yr)\", \"End Date (yr)\", \"Height ($atoms/cm^2/s$)\"]\n",
    "fig = mcmc_model.chain_summary(sampler, 20, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_model.plot_recovery(sampler, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from here the plan is to first of all find the ideal sinusoidal model based on the data points until the event. I then run this model and subtract it away from the data allowing me to determine the signal to noise ratio of the entire data instead of a subset. Then I simulate a series of events and minimize the $\\chi^{2}$ to determine the best fitting rectangular event. In addition I will have some criterion for the $\\chi^{2}$ as to when an event is detected allowing me to identify the minimum parameters of the event. I will then plot a contour plot of the $\\chi^{2}$ in the 2 dimensional parameter space. This will be the final product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to minimize the $\\chi^{2}$. After working so hard to get the `mcmc` I'm going to try and use this. The problem is because I was not using ticktack I can now immensly simplify the code by using the `SingleFitter` implementations provided by Q."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To minimize the $\\chi^{2}$ statistic I will need to isolate the data before the event and use this to determine the $\\sin$ parameters. This is going to require modifications to the `prod` function and also will require a better understanding of the plotting backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be easiest to modify the file. It is nice I must say to have got fucking nowhere all day. I'm going to go and pack now after merging these changes on github."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c4d728f571dc14aecd61e9c5a335d0795680d56501238c7b0344daa2ef0c43f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ticktack': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
